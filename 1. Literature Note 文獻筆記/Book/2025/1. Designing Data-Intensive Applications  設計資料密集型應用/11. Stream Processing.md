---
tags: []
date: 2025-06-01
time: 17:41
---
上一章的Batch Processing適合用來建立搜尋索引、推薦系統、分析...。但他的input是固定的Bounded。

Stream processing代表每隔一段時間，或是事件發生時，就進行batch processing處理。

## Transmitting Event Streams

事件是種immutable, 包含時間資訊的資料，可以被編碼成JSON或是binary。

事件會有通知者以及訂閱者。最好的方式是訂閱者在收到事件時被通知，而不是訂閱者不斷地去檢查是否有更新。

### Messaging Systems

messaging systems允許多個通知者以及訂閱者在同一個主題上。

注意的點：
1. 如果通知者生產的速度快於訂閱者消化的速度會怎麼樣？queue太大會發生什麼事？寫入disk會不會造成效能問題？
2. 節點失效時，訊息會怎麼樣？

#### Direct messaging from producers to consumers
這個機制的fault tolerant 基本上靠偵測與重新傳送（protocol detect and retransmitting packets），但這麼做的前提都是假設producer, consumer都在線上。

若consumer沒收到，需仰賴producer重新發送，此時producer crash的話，就會失去需要重傳的封包。

#### Message brokers
基本上是一個專門為了處理message queue而存在的database。運作的方式像是server，producer, consumer都是他的clients。

#### Message brokers compared to databases
有些message broker甚至可以參與兩階段提交。這讓他與database很像，但還是有些差異：

1. database不會自動刪除資料，message broker在確認傳送後就會刪
2. 為了避免因 consumer 處理太慢 而導致 整體吞吐量下降，我們傾向於設計並維持 message broker 的 working set（工作集）較小，也就是讓訊息儘快被消費，不在系統中累積
3. 過濾、搜尋方式不同
4. database可能容許資料過時，message broker則會通知clients有新資料

#### Multiple consumers

##### Load balancing
message broker挑一個consumer傳送訊息。
又稱shared subscription。

##### Fan-out
發送給所有訂閱者

這兩種模式可以並用，例如AB兩個group，訊息會送給每個group，但group中只有一個client收到訊息。


#### Acknowledgments and redelivery
client ack broker 收到之後，才可從queue刪除。
在load balancing會有個有趣的問題，導致message 抵達的順序不如預期。如果broker對每個consumer個別管理的話則不會出現這個問題。

### Partitioned Logs
log based message broker，想要保有持久性紀錄以及低延遲的通知。

#### Using logs for message storage

broker的分區，紀錄log的時候也會有offset，這個offset只會遞增。分區之間彼此互不影響。
藉由分區，即使要寫入disk也能維持高吞吐量。

#### Logs compared to traditional messaging
|特性|Log-based（如 Kafka）|傳統 messaging（如 JMS, AMQP）|
|---|---|---|
|**fan-out 支援**|✅ 天生支援（訊息不會被刪除，誰都可以讀）|✅ 需靠 topic/subscription 支援|
|**訊息會刪除嗎？**|❌ 不會，保留在 log 裡|✅ 讀完會刪除|
|**平行化策略**|**依 partition 分配給 consumer**（粒度粗）|**每筆訊息可單獨分配**（粒度細）|
|**最多消費者數量**|≤ partition 數|不限，可任意 fan-out|
|**訊息處理順序**|✅ 每個 partition 內保證順序|❌ 順序不保證或需額外設計|
|**處理慢的訊息影響？**|❌ 有 head-of-line blocking（整個 partition 卡住）|✅ 不一定卡住其他訊息|
|**適用場景**|高吞吐、快訊息、重視順序|單筆處理重、需細緻控制、順序不重要|

Kafka 限制一個 partition 只能被一個 consumer（同一 group）讀，是為了「**順序一致性**」的保證。

#### Consumer offsets
broker只需要記住client最後讀到的offset是多少，不需要追蹤所有訊息的ack。

#### Disk space usage
circular buffer的概念，disk多大，這段緩衝就多大。
consumer太慢會錯過資料。

#### When consumers cannot keep up with producers
disk buffer能夠爭取時間以人為修復slow consumer
並且就算consumer落後了很多（crash了)，也不必擔心這會影響 broker service。

#### Replaying old messages
Log-based broker 提供了像檔案一樣可重播的訊息記錄，讓你可以回溯、重試、做實驗，這讓資料整合、錯誤修復變得更容易。


## Databases and Streams

Database也能參考一下message broker。

replication log就是database將leader的寫入化為事件。
Total Order Broadcast則是在描述，我們能夠透過有順序的events使replica與源頭一致。

### Keeping Systems in Sync
![700](https://github.com/Vonng/ddia/raw/main/img/fig11-4.png)

### Change Data Capture (CDC)
![700](https://github.com/Vonng/ddia/raw/main/img/fig11-5.png)
The search index and any other derived data systems are just consumers of the change stream

#### Implementing change data capture
#### Initial snapshot
#### Log compaction
#### API support for change streams

### Event Sourcing
Event Sourcing 是把應用程式的每個「發生過的事件」存下來，不直接存最終結果，讓系統可以回放歷史、重建狀態，並具備極高的可追溯性與彈性。


> [!NOTE]
> ## 🔄 它跟 Change Data Capture (CDC) 有什麼差別？
> 
>
>
> |項目|Change Data Capture|Event Sourcing|
> |---|---|---|
> |資料怎麼來|系統用傳統資料庫，後面偷偷記下改動|一開始就記錄「事件」，資料來源就是事件|
> |資料性質|比較低階、像「row update」這種改動|比較高階、像「使用者取消課程」這種行為|
> |系統意識|資料庫自己運作、應用程式沒管這些改動|應用程式自己主動寫事件進 log|
> 

### State, Streams, and Immutability


## Processing Streams
如何處理stream資料
1. 寫入資料庫
2. 通知人類使用者
3. 輸出其他stream

### Uses of Stream Processing
#### Complex event processing CEP
Cep 有點像rgexp
監控stream，發現match時發出complex event

#### Stream analytics
#### Maintaining materialized views
Materialized view 是根據資料變化而即時更新的快取視圖，透過事件流與事件溯源方式維護它，可以實現一致性且高效的查詢，Kafka Streams 等工具能幫助你做到這件事。
#### Search on streams
為查詢建立索引

> [!NOTE]
> ## 🔧 實作想像：查詢被結構化成「可篩選的條件索引」
> 
> 假設有 10 萬條查詢，很多都跟 `amount` 有關：
> 
>
>> |查詢 ID|條件片段|
> |---|---|
> |Q1|amount > 100000|
> |Q2|amount BETWEEN 50000 AND 60000|
> |Q3|amount < 1000|
> 
> 系統會先建一個 **interval tree 或 B-tree** 來記錄所有涉及 `amount` 條件的查詢。  
> 當一筆事件 `amount = 80000` 到來時，系統會：
> 
> 1. 查詢索引中哪些查詢條件 **可能會命中**（例如包含 80000 的區間）。
>     
> 2. 僅對這些查詢進行後續比對（如 region、時間、次數條件等）。
>     
> 3. **跳過其餘明顯不會命中的查詢**（如 `amount > 100000`），節省運算資源。

#### Message passing and RPC
Message passing 著重在併發與模組溝通，stream processing 著重在資料持久化與轉換處理。雖然可以互相借鏡，但它們解決的是不同層次的問題。

### Reasoning About Time
#### Event time versus processing time
很多原因能讓處理被延遲，網路錯誤、效能、重啟。

事件發生的時間可能很穩定，但因為consumer重啟，會導致一段時間陡降，並在之後的一段時間處理事件的頻率爆升。
![600](https://github.com/Vonng/ddia/raw/main/img/fig11-7.png)


#### Knowing when you’re ready
#### Whose clock are you using, anyway?
使用client的時間：不可信，可能因為意外或蓄意的導致時間不正確
使用server的時間：正確，但是比較無法描述使用情況

透過三個時間戳來處理的個問題
1. client時間：event發生的時間
2. client時間：event發送給server的時間
3. server時間：收到event的時間

#### Types of windows


### Stream Joins
所謂的 stream、table 是在描述資料在系統中的角色與生命週期；而 join 的觸發點，是 stream 中新事件的到來；而這些 join 操作會即時去查詢狀態（table 或另一個 stream）來產出新資料。

> [!NOTE]
> ### ✅ **1. Stream–Stream Join：事件對事件的關聯**
> 📌 **情境：**
> - 假設你在做使用者行為分析，觀察「點擊商品」與「下單」之間的關聯。
> 
> 📅 **範例：**
> - 同一位使用者在 30 分鐘內點擊商品 A，又下單商品 A → 這兩個事件就會被 join 在一起。
> 
> 🔍 **用途：**
> - 分析行為路徑、偵測 fraud（例如短時間內大量異常操作）
> 
> ### ✅ **2. Stream–Table Join：即時查詢背景資料**
> 📌 **情境：**
> - 一個使用者登入事件（stream），你希望補上該用戶的 VIP 等級或地區資訊（table）
> 
> 🔍 **用途：**
> - enrich（增補）事件資訊，常用於 real-time recommendation、event logging 加入 user profile
> 
> 💡 **技術筆記：**
> - 為了效能，通常不會每次都查遠端資料庫，而是透過 **changelog stream → local cache** 來維護 profile 資料
> 
> ### ✅ **3. Table–Table Join：維護可查詢結果（物化視圖）**
> 📌 **情境：**
> - Twitter 想要維護每位使用者的 timeline（你 follow 誰，他們的 tweet 就出現在你 timeline 裡）
> 
> 🧩 **資料表：**
> - Follows Table：誰 follow 誰
> - Tweets Table：誰發了哪些 tweet
> 
> 📊 **用途：**
> - 當 follow / unfollow 或 tweet 發送時，馬上更新 timeline cache
> - 對應到 Materialized View 的即時維護：`SELECT * FROM tweets JOIN follows ...`
#### Stream-stream join (window join)
#### Stream-table join (stream enrichment)
#### Table-table join (materialized view maintenance)
#### Time-dependence of joins

> [!NOTE]
> ## ⏰ 時間依賴性的挑戰
> 
> 這三種 Join 都有「**根據什麼時間點的狀態來進行 join**」的問題：
> 
> ### 例子：
> 
> - 假設某人點擊了一篇推薦文章
>     
> - 推薦模型（或用戶 profile）之後更新了
>     
> - 那我們應該以「**點擊當下的模型版本**」還是「**最新的模型版本**」來判斷這次推薦是否成功？
>     
> 
> ### 解法（常見手段）：
> 
> - 使用 **slowly changing dimension（SCD）**：每次 profile 或 tax rate 變動，都產生新版本與 ID，讓事件記錄「它當下看到的是哪一版」
>     
> - 這樣就能使 join 過程**具備決定性（deterministic）**

| 類型                 | Input A           | Input B           | 狀態維護                     | 適合情境               |
| ------------------ | ----------------- | ----------------- | ------------------------ | ------------------ |
| Stream-Stream Join | 實時事件              | 實時事件              | 最近一段時間的事件（Window）        | CTR 分析、廣告點擊行為      |
| Stream-Table Join  | 實時事件              | Reference Table   | 本地快取 + CDC 更新            | 使用者行為 + Profile 配對 |
| Table-Table Join   | Reference Table A | Reference Table B | 持續同步維護 materialized view | 快取時間軸、推薦列表         |

### Fault Tolerance
  Batch processing的錯誤處理很簡單，只要重算一次就好。
  處理完畢時，使output file visible。但是stream不會有處理完的時候，他是無限的。

#### Microbatching and checkpointing
小batch的尺寸差不多在1秒。太大會導致delay，太小會導致overhead。

但是如果出錯的話，已經寫入的部分就無法被捨棄了。

#### Atomic commit revisited
在限制環境下可實踐。
Google Cloud Dataflow and VoltDB

#### Idempotence
冪等性

#### Rebuilding state after a failure
可能將state儲存起來，或是replay stream


### Summary
#### AMQP/JMS-style message broker
多個consumer
message 被 ack 之後就會被刪掉

適合順序不重要，不需要重新讀取的場景

#### Log-based message broker
一個partion指派給一個consumer node
適合需要產生衍生資料的場景

