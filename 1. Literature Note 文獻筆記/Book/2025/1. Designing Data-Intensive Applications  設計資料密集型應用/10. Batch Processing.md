---
tags: []
date: 2025-05-25
time: 22:22
---
### Services (online systems)
等待client的request，收到後要盡快回覆，反應時間以及可用性（availability）是重要的考量。

### Batch processing systems (offline systems)
讀取大量的input資料，需要跑一段時間。所以通常不會有使用者等他跑完，而是週期性的自動執行。
用吞吐量來考量表現。

### Stream processing systems (near-real-time systems)
相比於batch，通常在事件發生後就會執行

## Batch Processing with Unix Tools
設想每當server回應一則request時都會在log檔案新增一行紀錄。

log格式
```
$remote_addr - $remote_user [$time_local] "$request"
$status $body_bytes_sent "$http_referer" "$http_user_agent"
```
### Simple Log Analysis
假如我們今天想找出5個最常被訪問的網頁：
```shell
cat /var/log/nginx/access.log |
	awk '{print $7}' |
	sort |
	uniq -c |
	sort -r -n |
	head -n 5
```
用第七個元素，按照字母排序，之後把重複的行壓縮成一行（重複次數標在前面），按照重複次數由大至小排序，取前五個。

#### Chain of commands versus custom program
```ruby
counts = Hash.new(0)
File.open('/var/log/nginx/access.log') do |file|
file.each do |line|
url = line.split[6]
counts[url] += 1
end
end
top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5]
top5.each{|count, url| puts "#{count} #{url}" }
```

#### Sorting versus in-memory aggregation
如果資料量大，Unix的方式比較好，支援底層磁碟和排序。不大的話，在記憶體中操作就足夠了。

### The Unix Philosophy

> [!NOTE]
> 1. Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new “features”.
> 2. Expect the output of every program to become the input to another, as yet unknown, program. Don’t clutter output with extraneous information. Avoid stringently columnar or binary input formats. Don’t insist on interactive input.
> 3. Design and build software, even operating systems, to be tried early, ideally within weeks. Don’t hesitate to throw away the clumsy parts and rebuild them.
> 4. Use tools in preference to unskilled help to lighten a programming task, even if you have to detour to build the tools and expect to throw some of them out after you’ve finished using them.

sort比大部分程式語言實作的排序都來得好（借用磁碟與多緒），但只有在和Unix工具搭配使用時才有優勢。

#### A uniform interface
簡單來說就是檔案可以作為不同程序之間的介面。
例如stdin stdout socket

#### Separation of logic and wiring

#### Transparency and experimentation

## MapReduce and Distributed Filesystems
HDFS (Hadoop Distributed File System)

HDFS is based on the shared-nothing principle

HDFS中，每個機器會允許其他節點存取這台機器上的檔案。有個叫做NameNode的Server會記錄哪個檔案在哪一台機器上。

HDFS擴展的很好，他使用一般的軟硬體以及網路，就可以應用到上萬台機器，組成上百PB的容量。

### MapReduce Job Execution
1. 讀取檔案，切分成records
2. mapper function 抽取需要的key value e.g. `awk {print $7}`
3. 排序
4. reducer function e.g. `uniq -c`

MapReduce job 需要我們實踐mapper和reducer。

the role of the mapper is to prepare the data by putting it into a form that is suitable for sorting, and the role of the reducer is to process the data that has been sorted.

#### Distributed execution of MapReduce

![600](https://raw.githubusercontent.com/Vonng/ddia/main/img/fig10-1.png)

MapReduce 的一個核心特性：
> **程式碼是動態傳送給資料所在的機器，而不是把資料移動到程式碼所在的機器。**

這就是 **"move computation to data"** 的理念：**減少資料傳輸成本，提高效能與擴展性。**


MapReduce 把巨量資料分區後先局部排序，透過 hash 將相同 key 的資料發送到同一個 reducer，這樣就能在多機環境中高效地進行歸約與全域排序。

這個過程又叫shuffle


#### MapReduce workflows
不像unix pipeline，MapReduce使用workflows，執行完的結果會存到一個檔案，並讓下一個任務去讀取。


### Reduce-Side Joins and Grouping

denormalization 反正規化可以減少join的需求。是空間換取時間的操作。

MapReduce沒有index, join的概念。

#### Example: analysis of user activity events
#### Sort-merge joins
**Sort-Merge Join** 是在資料處理（尤其是批次系統、資料庫、MapReduce、Spark）中非常常見的一種 **高效能 join 方法**，尤其適合 **大規模資料集**。
 **Sort-Merge Join 是一種把兩個資料表先依 join key 排序，然後從頭到尾同步掃描，找出匹配記錄的 join 演算法。**
 
 透過 sort-merge join + secondary sort，MapReduce 可以高效地將多表關聯的資料按 key 群組並排序，讓 reducer 在單次掃描中完成複雜 join 操作，記憶體使用極少且不需額外通訊，特別適合批次大數據分析任務。

#### Bringing related data together in the same place

#### GROUP BY

#### Handling skew
在社群媒體上，擁有百萬追蹤的名人做了某些留言的動作，收集這資料到單一的reducer上會導致 *skew* 或稱 *hot spot*
[[6. Partitioning 分區#Skewed Workloads and Relieving Hot Spots]]


### Map-Side Joins
不reduce也不排序
#### Broadcast hash joins
**Broadcast hash join** 是一種將**小表格複製到所有節點記憶體中**，然後用 hash join 與大表做匹配的 join 策略，常用於分散式系統中加速小表 join 大表的情境。

#### Partitioned hash joins
**Partitioned hash join** 是一種將兩張表依照 join key 分區後，**對每個分區分別建立 hash join** 的方法，適用於資料太大、無法整體放入記憶體時的分散式 join 策略。

### The Output of Batch Workflows
The output of a batch process is often not a report, but some other kind of structure.

#### Building search indexes
#### Key-value stores as batch process output
#### Philosophy of batch process outputs

### Comparing Hadoop to Distributed Databases
Hadoop is somewhat like a distributed version of Unix, where HDFS is the filesystem and MapReduce is a quirky implementation of a Unix process.

#### Diversity of storage
實務上，資料用最原始的方式存下來，會比事先（為了資料庫）建模好的資料好用。

Hadoop 的 ETL 模型將資料建模與收集分開，使得資料可以先被儲存起來，再由 MapReduce 等工具批次清洗與轉換，最後才建模與載入資料倉儲分析。這種流程提高了彈性，也帶來了 schema-on-read 的資料處理風格。

#### Diversity of processing models
MapReduce使工程師能在大量資料上簡單地運行程式。

#### Designing for frequent faults
電腦可能會為了其他優先度高的任務而中斷其他優先度低的任務。

## Beyond MapReduce

### Materialization of Intermediate State
#### Dataflow engines
#### Discussion of materialization

### Graphs and Iterative Processing
### High-Level APIs and Languages
high-level interfaces not only make the humans using the system more productive, but they also improve the job execution efficiency at a machine
level.
#### The move toward declarative query languages
#### Specialization for different domains
