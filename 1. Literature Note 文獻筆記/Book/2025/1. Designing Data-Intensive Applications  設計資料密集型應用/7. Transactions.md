---
tags: []
date: 2025-05-01
time: 21:38
---

transaction是一種讓應用程式將一系列讀取、寫入組合成一個邏輯單元的方式。

交易中的所有的讀取、寫入被作為一個操作執行。必須要所有動作都成功才算結束，否則要退回去。

有了交易的概念，應用程式的錯誤處理可以變得簡單，因為不必擔心部分錯誤（有些成功、有些失敗）。

交易被創立出來的目的，就是為了應用程式簡化程式模型。有了交易，應傭程式可以忽略一些淺在錯誤的場景和俵發的問題，因為資料庫已經幫忙處理好了。

是否需要交易取決於交易的安全性以及他所需要的花費。而且乍看之下這個概念很簡單，但是台面下他隱藏著許多複雜之處。

## The Slippery Concept of a Transaction
現今很多的資料庫服務都出奇得與IBM System R很像。

在 NoSQL 資料庫崛起的過程中，傳統的交易（transactions）是最常被犧牲的特性。許多系統為了擴展性，完全不支援 ACID 交易，或是將「交易」這個詞降格使用，只代表一些非常弱的保證。

很多人認為transaction會阻礙擴展性，但事情沒有這麼單純。重點還是這之間的取捨。


### The Meaning of ACID
不同的實作，他們對ACID可能有不同的解釋，例如 *isolation*。所以如今ACID更像是一個market term。

#### Atomicity 原子性（可退出性）
指「不可再被分割、變小」的事物。
這個詞在不同情境中也有不同的含義。

例如：多執行緒時，atomicity代表其他執行緒無法看到「執行到一半的」的結果。
但是在這裡（ACID），他指的與併發沒有關係。反而這個概念被  *isloation* 所涵蓋了。

準確的說， *atomicity* 在這裡指的是：
client想要進行多個寫入，但是中途發生了錯誤。這可能是程序crash、網路中斷、磁碟空間已滿、或是其他一體性被違反的情況。
我們將多個寫入組合成一個 atomic transaction 原子交易。如果中途失敗，那這個交易的內容都要被廢除。

原子性簡化了問題，如果交易被廢止，那麼我們可以保證沒有變動發生。

或許 abortability 會比 atomicity 這個術語來的貼切。

##### **技術實作方式：**
- 資料庫使用 **寫前日誌（Write-Ahead Log, WAL）**，先記下操作意圖，再實際執行。
- 若任一操作失敗，系統會使用 WAL 回滾（rollback）已執行的部分。

#### Consistency 一致性
這裡的「一致性」代表我們對我們的資料有宣告一個規則，無論何時都不得違反。

如果資料一開始就是合法的，且所有寫入也都沒有違反規則，那這個一致性就能被滿足。

但是，這個規則是靠應用程式定義的。資料庫的責任頂多就是檢查外鍵與唯一鍵。
##### 📌 外鍵一致性（Foreign Key Consistency）簡單定義：
> 在資料表中，**外鍵欄位的值必須參照到另一張表中已存在的主鍵（或唯一鍵）值**。  
> 換句話說：**你不能指向不存在的東西。**

atomicity, isolation, durability 都是資料庫的特性，但是唯獨consistency是屬於應用程式。

所以C甚至不算真的可以算到ACID裡面。

#### Isolation 隔離性
資料庫常常會被client同時存取。當存取的資料是同一筆時，就會發生concurrency problems(race conditions)。

一個很簡單的例子是：兩個client同時想對一筆資料 `+`1，那預期結果應該要為`+2`，但是在併發的情況下，結果會只有`+1`。

ACID的isolation指的是他們彼此獨立，不會互相影響。
這又稱serializable isolation（需要一個接在一個後面進行）。但這種做法很耗效能，有些資料庫甚至不會實作他，取而代之用個更簡單的版本：snapshot isolation。

#### Durability 永續性
資料庫要保證交易一但被提交了，我們就不需要擔心他會消失。即使硬體出錯或是資料庫崩潰。

在單節點資料庫中，durability基本上代表資料會被存進磁碟或是SSD裡。通常也會包含 write-ahead log，可以從損壞的資料重建。
再複製型資料庫中，durability代表資料已被複製到其他節點。我們必須等待所有節點的資料都被寫入完成，交易才算成功。

除了外部因素，也有可能因為檔案系統、儲存引擎有bug或是損毀。這些需要從歷史備份重建。


### Single-Object and Multi-Object Operations

舉個電子郵件的例子：
計算未讀取郵件數量是很耗時間的，所以我們可能會另外設定一個變數來表示他。

情境一
1. a上傳了電子郵件
2. b讀取，發現有未讀信件但是未讀數量顯示為0
3. a更新未讀數量
那這就會很奇怪。這應該是 *Isolation* 來防止的事。

情境二
1. a上傳了電子郵件
2. a更新未讀數量，但是失敗
*Atomicity* 在寫入數量失敗時，連同插入電子郵件的操作都要回滾。

Multi Object的交易，需要一些方式保證他們的讀取、寫入在同一個交易中。
在關聯式資料庫中，TCP連線中：任何在`TRANACTION`和`COMMIT`之間的操作，都被視作同筆交易。

但在非關聯式資料庫中就沒有這種圈組方式。資料庫可能會處在只有部分被更新的狀態。

#### Single-object writes
原子性可透過log來達成。
隔離性透過lock來完成。（同時只能有一個thread存取一個object）

雖然單物件操作像 `compare-and-set` 很有用，可以防止 race condition，但它**不是完整的 transaction**。有些資料庫為了行銷，誇大這類操作是「ACID」或「交易」，但這樣的說法會誤導使用者。**真正的交易，應該是能跨多個資料項目、一次完成多個操作的機制。**


#### The need for multi-object transactions
許多分散式系統捨棄多物件的交易，因為在多個partition中會變得很難實作，尤其當我們有高取用、高表現的需求時。

但我們還是需要他
- 關聯式資料庫中，通常有外鍵指向另外一個table，multi-object transaction保證這個參照還是有效的
- 文件型資料庫中，因為denormalization，我們需要一次更新多個文件
- 有次級索引時，要等他被更新

#### Handling errors and aborts
並不是所有資料庫都會跟隨ACID的。像leaderless replication是盡可能保留已完成的部分，保持資料正確是應用程式的責任。

另外，雖然退出交易是個簡單有效的錯誤處理機制，但他也有缺點

- 當交易已完成，但是server通知client時出了問題，client會以為他失敗了，導致這個交易被重複執行
- 若是因為過載導致的錯誤，重試交易只會讓情況變糟
- 暫時性的錯誤才值得重試


## Weak Isolation Levels
資料庫為了減輕開發者處理併發問題的負擔，會提供一種保證：*transaction isolation* 。我們會假裝沒有併發這個問題。
*serializable transaction* 保證交易會像是依序般的執行。

但是serializable isoloation是很花效能的，很多資料庫不想負擔。所以他們會用一個較弱的隔離性，可以在某些情況下處理併發問題。但這些情況都很複雜且容易產生bug。

所以比起盲信工具，我們應該培養我們對併發問題的了解，以及如何預防他們。

### Read Committed
1. 只讀取乾淨的資料（no dirty reads）
2. 只會寫在乾淨的資料上(not dirty writes)

#### No dirty reads
當交易處理到一半時，還沒有提交或是回滾，此時讀取該資料就稱為 *dirty read* 。

dirty read 會導致：
- 看到更新到一半的資料，就如上面電子郵件的例子，雖然有新郵件，但是未讀數量仍是0
- 如果資料回滾的話，那就等於讀到不存在的資料了

#### No dirty writes
如果我們覆寫了一個uncommitted value，那就是 *dirty write* 了。通常透過等待資料committed or aborted才可繼續。

例如有兩個操作：更新Listings, 更新Invoices。如果A, B 兩人以這樣的順序操作的話：
A->Listing
B->Listing
B->Invoices
A->Invoices
那會導致整個資料錯亂

> [!NOTE]
> ### 📘 補充：Read Committed 是很多資料庫的預設隔離等級，例如：
> - SQL Server
> - Oracle
> - PostgreSQL（在 snapshot 模式下用 snapshot isolation，但表現類似 read committed）

### Snapshot Isolation and Repeatable Read
在時間1讀取交易前的資料，並在時間2讀取交易後的資料，這會造成 *nonrepeatable read*。

很多時候只要重新讀取一次就沒事了，但有些情況無法容許：
1. 備份。備份需要時間，但這段時間內接受其他寫入，就會造成資料一部分新一部分舊
2. Analytic queries and integrity checks

快照隔離是最常用來處理這類問題的方法。

#### Implementing snapshot isolation
*multi-version concurrency control (MVCC)*
資料庫會為每個提交記錄一個版本的資料，因為某些正在進行中交易會需要讀取。

例如一個物件的資料被更新時，目前的版本會被標示刪除，並新增一個版本。

#### Visibility rules for observing a consistent snapshot
交易的id會用來決定他可以看到哪些資料。
1. 當下建立資料的交易已經提交了的資料
2. 當下刪除該資料的交易還沒有被提交的資料

這種方式只會產生很小的額外開銷

#### Indexes and snapshot isolation

一個簡單的方式是讓key指向所有版本的物件。
實務上有不同種的實作方式。
PostgreSQL盡量讓不同版本在同一個page上，減少更新index的機會。
另種方式是 B-Trees  *append-only/copy-on-write*。更新的資料時，從從該資料一路到root建立一個克隆，並讓他指向新資料。
這樣舊資料也不會被改變。
這麼做有一個好處是，克隆的root就會直接指到該版本能看到的資料，不需要多做filter的行為。

不管怎麼說，都需要背景執行打包和垃圾回收。

#### Repeatable read and naming confusion
命名、實作方式並沒有一個太統一的共識，就算有定義

### Preventing Lost Updates
A read data 42
B read data 42
A write data 42 + 1
B write data 42 + 1
但其實應該要是44

常見的發生情境
1. 更新計數器或帳戶餘額
2. 在JSON資料中，向list插入一個值
3. wiki page 整頁更新

#### Atomic write operations
避免讀取->修改->寫入 *read-modify-write* 的三步驟，直接對資料庫操作資料。這通常是最好的選擇。
```SQL
UPDATE counters SET value = value + 1 WHERE key = 'foo';
```

就算是文件型資料庫也有提供對JSON特定部分修改的原子操作。Redis也有可以修改資料結構的操作（如priority queue）。
但wiki這種的就無法了。

原子操作通常可以透過lock或是只讓一個thread寫入來達成。

不幸的是，[[ORM  <Object-Relational Mapping>]] 容易使人寫出 read-modify-write 而不是原子操作。
雖然這通常不是問題，但很多測不出來的bug都出自這裡。

#### Explicit Locking
如果資料庫無法有atomic operation，那只能靠應用程式去鎖住你要更新的資料了。

想像多人遊戲中，可以有多個玩家去移動同一個實物。此時一個資料庫的原子操作就不適合用來處理，因為這可能需要更細緻的操作以符合遊戲邏輯。

#### Automatically detecting lost updates
前兩種方法都是讓他們保持依序操作來防止lost updates的。
有另外一種方式，允許平行操作，但會有一個 transaction manager，當他偵測到lost updates時，會停止交易。
這麼做的好處是它可以有效率的與snapshot isolation搭配執行。
PostgreSQL可以做到。但是MySQL無法。

Lost update detection 是個很棒的功能，因為他不需要應用程式去煩惱lock和atomic operation。

#### Compare-and-set
資料庫不保證交易時會看到他。

透過在準備要更新資料時，檢查資料的值與當初讀取時是否還一樣，否則不給更新。

不過，當資料庫允許你讀取舊資料快照時，這個方式就無法防止lost updates了。

#### Conflict resolution and replication

Locks and compare-and-set的操作預設節點上的資料都要是最新的才能成立，所以這在replicated nodes情境中無法使用。

參考[[5. Replication#Handling Write Conflicts]]

原子操作在複製情境中可以運作得挺不錯的，尤其是有交換性的操作（commutative），像是計數器這種操作順序不影響結果的情境。

### Write Skew and Phantoms
當我們需要滿足某些條件才能寫入時，我們可能會遇到讀取條件之後，該條件被其他人改變了，所以這個條件判斷實際上有可能就是錯的了。
#### Characterizing write skew
這不是 *dirty write* 也不是 *lost update*，因為這個情境並沒有寫入在同一個資料上。

- 原子單物件操作在這個情境沒有防範作用
- 快照隔離沒有用
- 能用的是serializable isolation和lock

#### More examples of write skew
 - Meeting room booking system
 - Multiplayer game
 - Claiming a username
 - Preventing double-spending

#### Phantoms causing write skew
先讀再寫分成兩個交易  就有可能形成phantom 

#### Materializing conflicts 具體化衝突

> [!NOTE]
> #### ❓什麼是 **Phantom Read（幻影讀）**？
> - 指的是一個交易在兩次查詢同一條件時，**結果卻出現了額外的 row**。
> - 例如第一次查詢 `WHERE age > 30` 得到 3 筆資料，結果某個交易插入了一筆 age=35 的資料，第二次查就變成 4 筆了。
> 
> 這是一種隱藏的資料變動，你**沒辦法針對「不存在」的 row 加鎖**來預防這種情況。
> 
> ### ✅ 那什麼叫 **Materializing Conflicts**？
> 這是一種解法：
> > **把可能出現「phantom」的情況轉成「具體 row」上的鎖定行為。**
> 舉例：
> - 原本你查 `age > 30`，無法預先知道誰會插入符合這個條件的資料。
> - 那你乾脆把這個條件查詢範圍「**對應到一個索引區間**」來鎖定。
> - 例如鎖住 age=31 到 age=150 這一段範圍 → 誰要插入 age=35 就會被擋下來。
> 這就是把「phantom（不存在但可能出現的資料）」轉換成「**具體的索引範圍鎖（range lock）**」的技巧。
> 
> ---
> ### ✅ 總結：
> 
> 這句話的意思是說：
> 
> > 原本 phantom read 是一種你沒辦法預先鎖住的「幽靈」型衝突，而這個技巧（materializing conflicts）是把那種幽靈具體化成一組 row 上的鎖，讓它變成可以控制的同步點。
> 

但這種方式容易產生bug，也讓併發控制機制影響到了應用程式的資料模型。

這種方式應被視為最終手段，一般應採取serializable isolation。

## Serializability
**Serializable isolation（可序列化隔離級別）** 通常被視為**最強的隔離等級**。

現今資料庫用了這些技巧，以保證序列化隔離

- Actual Serial Execution
- Two-phase Locking
- Serializable Snapshot Isolation

### Actual Serial Execution
所有的交易都在同一個執行緒上

- RAM要夠便宜到，我們能將active dataset存在記憶體中，這樣才夠快
- 線上交易處理 (OLTP)的交易數量夠簡短

#### Encapsulating transactions in stored procedures
盡可能減少網路、disk I/O 時間，應用程式要視姦將交易程式碼提交給資料庫，稱之為stroed precedures。

#### Pros and cons of stored procedure
缺點
- 每個資料庫都有自己的語言
- 難以掌握
- 糟糕的資料庫程式碼會比糟糕的應用程式程式碼影響更深遠

不過這些缺點是可被克服的，像是VoltDB uses Java, Redis uses Lua

VoltDB也可以將stored procedures用於複製上，但這些procedures得是完全一致的 (deterministic)，如果交易有使用到時間的話，甚至得用特殊的API。

#### Partitioning
每個分區可以有自己的執行緒，所以有幾個cpu core就可以分幾區來提升效率

但有些交易要使用跨分區的資料，這樣的效率差異會到10～100倍 
orders of magnitude below

能否做到單一分區交易，高度依賴應用程式資料的結構。

#### Summary of serial execution

以下情境或限制能使序列化隔離變得可行
- 每個交易要夠簡短
- dataset要在記憶體中
- 寫入吞吐要夠低，否則要利用分區加速
- 跨分區的使用情境限制會很嚴苛

### Two-Phase Locking (2PL)

在快照隔離中有一個原則：readers never block writers, and writers never block readers
在2PL中，與此原則**正相反**。

#### Implementation of two-phase locking
每個物件上會有一個lock，lock會有兩個狀態：*shared mode*, *exclusive mode*

- 讀取時，資料變為 shared mode
- 寫入時，資料會變為 exclusive mode，其他交易無論什麼狀態都不可持有lock
- 直到交易結束之前，lock都由該交易持有。二階段的名稱由此而來

當遇到deadlock時，資料庫會強制退回其中一個交易以解除deadlock。應用程式得重新嘗試。

#### Performance of two-phase locking
2PL的吞吐量及反應時間是遠糟於弱隔離的。

如果有個緩慢的交易他lock住很多資源的話，那很容易整個系統會停擺。

deadlock的發生機率也比read committed isolation來得高。deadlock越頻繁，代表越多的重試與資源浪費。

#### Predicate locks
Predicate lock 是針對條件的鎖，用來防止 phantom read。它不只鎖住現有資料，也阻止符合條件的新資料被插入。

#### Index-range locks
他不像predicate locks那樣準確（他會鎖住更大的範圍），但他有更小的overhead。

### Serializable Snapshot Isolation (SSI)
目前為止介紹的序列化隔離都效能蠻糟的，但SSL可能是個救星。

#### Pessimistic versus optimistic concurrency control
2PL 是悲觀併發控制：為了保證不出錯，我們只好等到狀況安全了之後才行動。
SSL則是樂觀併發控制：比起不做任何動作，我們繼續執行，並希望事情不會出錯。

他的壞處是，如果競爭很激烈的話，常會觸發重試，這導致表現變得更差。
相反，如果競爭不激烈的話，樂觀會比悲觀表現來得好。
為了降低競爭，也可以用commutative atomic operations ([[#Preventing Lost Updates]])。

SSL在快照隔離的基礎上，增加了檢測序列化衝突和決定哪個交易該中止。

#### Decisions based on an outdated premise

資料庫要怎麼知道一個query的結果已經改變了？

##### Detecting stale MVCC reads
在MVCC中，我們讀取時可能會故意忽略某些已經寫入但還沒committed的資料。當我們提交時，我們檢查這些寫入是否已經提交了，是的話，這個交易就得中止。
這種衝突稱為 **read skew** 或 **stale read**

##### Detecting writes that affect prior reads
與前者的差異在於，較晚的交易讀取時，較早的交易還沒有寫入

資料庫被讀取時，會記錄是哪些交易讀取了他。當資料被寫入時，資料庫會檢查哪些交易讀過這些資料，並通知該交易說這些資料過時了。

#### Performance of serializable snapshot isolation

> [!NOTE]
> ### **讀寫追蹤的粒度是一種效能與精度的權衡**
> - 若追蹤很細（例如記錄每次讀寫的欄位）→ 精確地判斷哪些交易該 abort，但會有高開銷。
> - 若追蹤較粗略 → 開銷小，但會有**不必要的 abort**。
> 
> ### **不是所有被覆寫的資料都要導致 abort**
> - 在某些情況下，即使讀到了被覆蓋的資料，仍可證明結果是 **serializable**。
> - PostgreSQL 利用這種理論來減少不必要的交易失敗。
> ### **SSI 的最大優點：非阻塞**
> - 與兩階段鎖（2PL）相比：
>     - **讀不會擋寫，寫也不會擋讀**（同樣延續 Snapshot Isolation 的特性）。
>     - 所以 **查詢延遲更可預測、變異性更小**。
>     - **唯讀查詢可在 snapshot 上執行，不需加鎖** → 特別適合 **讀多寫少的場景**。
> 
> ### **SSI 比序列化執行（Serial Execution）更具可擴展性**
> - 例如 FoundationDB：
>     - 分散式偵測衝突（serializability conflict）
>     - 可以跨多機運作，不受限於單一 CPU 核心。
>     - 支援跨分區的讀寫，仍保持 serializable 隔離等級。
> 
> ### **Abort 率決定整體效能**
> - 長時間執行的 **讀寫交易** 比較容易衝突、導致 abort → 因此必須保持簡短。
> - 但 **唯讀交易即使很長，也比較不受影響**。
> - 總體而言，SSI 對慢交易的敏感度 **比 2PL 或 serial execution 小**。

